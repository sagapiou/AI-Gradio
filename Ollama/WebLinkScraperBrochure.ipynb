{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c438a5b2-044f-4688-9edc-53cb0870ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalimports\n",
    "import os\n",
    "import requests\n",
    "import ollama\n",
    "import json\n",
    "from typing import List\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12f4ca71-539d-4476-a98d-f1b767aae4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for calling ollama\n",
    "model = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9c9e63a-8561-42a8-93c3-1fd295a354bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we check a website and return a topple with the webpage content and a list of all the links\n",
    "def webPage(url):\n",
    "    header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"}\n",
    "    \n",
    "    response = requests.get(url, headers=header)\n",
    "    body = response.content\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    webTitle = soup.title.string if soup.title else \"No title found\"\n",
    "    if soup.body:\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        webText = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "    else:\n",
    "        webText = \"\"\n",
    "    links = [link.get('href') for link in soup.find_all('a')]\n",
    "    webLinks = [link for link in links if link]\n",
    "    return f\"Webpage Title:\\n{webTitle}\\nWebpage Contents:\\n{webText}\\n\\n\", links        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b128dfd3-59c2-42ff-b4f4-a93ae81bfcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the system prompt that we define the exact type of json we are execting\n",
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb4f79ea-b0b3-46fa-954c-1eb85d318aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the user prompt that we initially pass the url and expect the links\n",
    "# from these links we ask the AI to decide which are the most relevant for the system prompt ... i.e a \n",
    "# company brochure\n",
    "def get_links_user_prompt(url):\n",
    "    _ , links = webPage(url)\n",
    "    user_prompt = f\"Here is the list of links on the website of {url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6bb4607-6d86-4d39-a3cf-8133bed1d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the olama response \n",
    "def get_links(url):\n",
    "    response = ollama.chat(\n",
    "        model=model, \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "      ], format='json'\n",
    "    )\n",
    "    return json.loads(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7da62afd-9ee5-4b0b-a69c-4f5673e784c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# her ewe create the entire content we wil be passing to the AI\n",
    "# along with the content of all the relevant links of the main page\n",
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    mainPageContent, _ = webPage(url)\n",
    "    result += mainPageContent\n",
    "    links = get_links(url)\n",
    "    #print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        try:\n",
    "            result += f\"\\n\\n{link['type']}\\n\"\n",
    "            subPageContent, _ = webPage(link[\"url\"])\n",
    "            result += subPageContent\n",
    "        except Exception as e:\n",
    "            _\n",
    "            #print(f\"An error occurred for this webpage: {e}. Specific page will be ignored\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6392839-e3e0-473c-89bd-57b0a2fb81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on the tone we get a different answer\n",
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4318076c-bbba-4323-8839-bc1aa809e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f013764-4b14-46e4-9245-0fcaeaf602b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the stream part in combination to the markdown is in order to get a\n",
    "# stream like experience in the jupyter notebook\n",
    "def createBrochureAndStreamMarkdown(company,url):\n",
    "    streamingResponse = ollama.chat(\n",
    "        model=model, \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt(company,url)}\n",
    "      ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in streamingResponse:\n",
    "        response += chunk.get('message', {}).get('content', '') or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a13693b-5885-4b4e-98d8-8c61679ae780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#createBrochureAndStreamMarkdown(\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4afe78f5-d00c-4d5f-9c8a-45c3735f2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iface = gr.Interface(fn=createBrochureAndStreamMarkdown,\n",
    "#                      inputs=[gr.Text(), gr.Text()], \n",
    "#                      outputs=gr.MultimodalTextbox())\n",
    "# iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488fc16-60c5-4061-a784-62328a80e32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
